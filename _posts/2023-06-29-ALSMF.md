---
title: "Reject Modernity, Embrace Tradition: The Significance Of Research Design And A Revisiting Of Matrix Factorization"
date: 2023-06-29
---

# When you're a hammer, everything looks like a nail. #

We often overplay the importance of newer and shinnier algorithms compared to older and forgotten techniques in machine learning. Two papers recently have stood out and demonstrated this better than anything else.

1. Think back to the beginnings of Netflix. Their recommendation system had an RMSE (error) of .9513, and would give a million dollars to the first team to lower that by 10%. It took about three years until we got the prize. All that was used to do this for this time was Matrix Factorization, and the better understanding of how to implement and use the algorithm.

"On the Difficulty of Evaluating Baselines" by Rendle et al. is an incredibly eye-opening look into how improper baselines in the development of recommendation systems leads to the inflated results of papers. Over the years researchers put out models that were acrewing better and better results. These results were ficticious, as the preprocessing and handling of data resulted in better results rather than the techniques themselves.

Bayesian timeSVD++ flipped

2. "A ConvNet for the 2020s" by Liu et al. is another example of poor 
